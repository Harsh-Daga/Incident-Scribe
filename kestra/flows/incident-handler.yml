id: incident-handler
namespace: incident.response

description: |
  Production-ready AI-powered incident analysis and remediation workflow.
  - Receives incident data via webhook from monitoring tools
  - Queries Supabase for historical incidents (same service/patterns)
  - Analyzes using Gemini AI for root cause and remediation
  - Saves AI analysis results back to Supabase
  - Uses Kestra KV store for all secrets (no hardcoded keys)

labels:
  env: production
  team: sre

inputs:
  - id: incident_data
    type: JSON
    description: |
      Incident details from webhook. Required fields:
      - id: External incident ID
      - service: Affected service name
      - severity: CRITICAL, HIGH, MEDIUM, or LOW
      - title: Incident title
      - organization_id: Organization UUID
      - logs: Array of log entries
      - metrics: Object with error_rate, latency_p95_ms, etc.
      - context: Object with host, region, version, etc.
    required: true

tasks:
  # Task 1: Log incoming incident
  - id: log_incident
    type: io.kestra.plugin.core.log.Log
    message: |
      ========================================
      üì¢ INCIDENT RECEIVED
      ========================================
      ID: {{ inputs.incident_data.id }}
      Service: {{ inputs.incident_data.service }}
      Severity: {{ inputs.incident_data.severity }}
      Title: {{ inputs.incident_data.title }}
      Organization: {{ inputs.incident_data.organization_id }}
      Timestamp: {{ inputs.incident_data.timestamp }}
      ========================================

  # Task 2: Query Supabase for historical incidents (same service)
  - id: fetch_historical_incidents
    type: io.kestra.plugin.core.http.Request
    description: Query Supabase for similar historical incidents in the same organization
    uri: "{{ kv('SUPABASE_URL') }}/rest/v1/incidents"
    method: GET
    headers:
      apikey: "{{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
      Authorization: "Bearer {{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
    contentType: application/json
    options:
      connectTimeout: PT10S
      readTimeout: PT30S
    queryString:
      organization_id: "eq.{{ inputs.incident_data.organization_id }}"
      service: "eq.{{ inputs.incident_data.service }}"
      select: "id,external_id,title,severity,status,logs,metrics,created_at"
      order: "created_at.desc"
      limit: "5"

  # Task 3: AI Agent - Analysis (Gemini)
  - id: ai_agent_analyze
    type: io.kestra.plugin.core.http.Request
    description: AI Agent analyzes incident using Gemini API with historical context
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
    timeout: PT60S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "You are an expert SRE AI Agent analyzing a production incident.\n\n## CURRENT INCIDENT\n- ID: {{ inputs.incident_data.id }}\n- Service: {{ inputs.incident_data.service }}\n- Severity: {{ inputs.incident_data.severity }}\n- Title: {{ inputs.incident_data.title }}\n- Error Rate: {{ inputs.incident_data.metrics.error_rate | default(0) }}\n- Latency P95: {{ inputs.incident_data.metrics.latency_p95_ms | default(0) }}ms\n- Region: {{ inputs.incident_data.context.region | default('unknown') }}\n- Host: {{ inputs.incident_data.context.host | default('unknown') }}\n- Version: {{ inputs.incident_data.context.version | default('unknown') }}\n\n## LOGS\n{{ inputs.incident_data.logs | join('\n') }}\n\n## HISTORICAL INCIDENTS (same service)\n{{ outputs.fetch_historical_incidents.body }}\n\n## ANALYSIS REQUIRED\nProvide a comprehensive analysis in JSON format:\n{\n  \"root_cause\": \"Detailed root cause explanation\",\n  \"root_cause_confidence\": \"HIGH|MEDIUM|LOW\",\n  \"error_clusters\": [\n    {\"pattern\": \"error pattern\", \"count\": 1, \"severity\": \"HIGH|MEDIUM|LOW\"}\n  ],\n  \"impact_analysis\": {\n    \"affected_users\": \"Estimation of affected users\",\n    \"business_impact\": \"Business impact description\",\n    \"technical_impact\": \"Technical systems affected\"\n  },\n  \"proposed_fixes\": [\n    {\"fix\": \"specific fix\", \"priority\": \"P0|P1|P2\", \"effort\": \"HIGH|MEDIUM|LOW\", \"risk\": \"HIGH|MEDIUM|LOW\"}\n  ],\n  \"remediation_commands\": [\n    {\"command\": \"safe command only: restart|scale|rollback|health-check\", \"purpose\": \"what it does\", \"safe\": true}\n  ],\n  \"preventive_measures\": [\"list of preventive actions\"],\n  \"runbook_links\": [\"relevant documentation links\"]\n}\n\nBe specific, technical, and actionable. Focus on root cause and immediate fixes."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.3,
          "maxOutputTokens": 4000,
          "responseMimeType": "application/json"
        }
      }

  # Task 4: Parse AI response and extract analysis
  - id: parse_ai_analysis
    type: io.kestra.plugin.scripts.python.Script
    description: Parse AI response and prepare data for saving
    warningOnStdErr: false
    docker:
      image: python:3.11-slim
    script: |
      import json
      import sys

      # Parse AI response
      ai_response = '''{{ outputs.ai_agent_analyze.body }}'''
      
      try:
          response_data = json.loads(ai_response)
          # Extract the generated text content
          if 'candidates' in response_data:
              text_content = response_data['candidates'][0]['content']['parts'][0]['text']
              analysis = json.loads(text_content)
          else:
              analysis = response_data
      except Exception as e:
          print(f"Error parsing AI response: {e}", file=sys.stderr)
          analysis = {
              "root_cause": "Unable to parse AI response",
              "root_cause_confidence": "LOW",
              "error_clusters": [],
              "impact_analysis": {"affected_users": "Unknown", "business_impact": "Unknown", "technical_impact": "Unknown"},
              "proposed_fixes": [],
              "remediation_commands": [],
              "preventive_measures": [],
              "runbook_links": []
          }
      
      # Output as JSON for next tasks
      print(json.dumps(analysis, indent=2))
    outputFiles:
      - "*.json"

  # Task 5: Decision branching based on severity
  - id: severity_decision
    type: io.kestra.plugin.core.flow.Switch
    description: Route based on incident severity
    value: "{{ inputs.incident_data.severity | upper }}"
    cases:
      LOW:
        - id: handle_low
          type: io.kestra.plugin.core.log.Log
          message: |
            ü§ñ AI DECISION: AUTO-REMEDIATION
            Incident {{ inputs.incident_data.id }} - Low severity
            Action: Automated remediation can proceed
            Confidence: HIGH

      MEDIUM:
        - id: handle_medium
          type: io.kestra.plugin.core.log.Log
          message: |
            ü§ñ AI DECISION: APPROVAL REQUIRED
            Incident {{ inputs.incident_data.id }} - Medium severity
            Action: Human review required before remediation
            Approval URL: https://incident-scribe.vercel.app/incident/{{ inputs.incident_data.id }}

      HIGH:
        - id: handle_high
          type: io.kestra.plugin.core.log.Log
          message: |
            ü§ñ AI DECISION: IMMEDIATE ESCALATION
            Incident {{ inputs.incident_data.id }} - High severity
            Action: On-call team paged, war room initiated
            Priority: P1

      CRITICAL:
        - id: handle_critical
          type: io.kestra.plugin.core.log.Log
          message: |
            ü§ñ AI DECISION: CRITICAL ESCALATION
            Incident {{ inputs.incident_data.id }} - Critical severity
            Action: All hands alert, executive notification
            Priority: P0

  # Task 6: AI Agent - Remediation Recommendations
  - id: ai_agent_remediation
    type: io.kestra.plugin.core.http.Request
    description: Generate specific remediation steps
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
    timeout: PT60S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "Based on this incident analysis, provide detailed remediation steps:\n\nINCIDENT: {{ inputs.incident_data.id }}\nSERVICE: {{ inputs.incident_data.service }}\nSEVERITY: {{ inputs.incident_data.severity }}\nANALYSIS: {{ outputs.parse_ai_analysis.vars.stdout }}\n\nProvide:\n1. IMMEDIATE ACTIONS (step-by-step commands)\n2. VERIFICATION STEPS (how to confirm fix worked)\n3. ROLLBACK PROCEDURE (if fix fails)\n4. MONITORING CHECKLIST (what to watch after fix)\n\nFormat as markdown with clear sections."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.4,
          "maxOutputTokens": 3000
        }
      }

  # Task 7: AI Agent - Documentation/Postmortem
  - id: ai_agent_documentation
    type: io.kestra.plugin.core.http.Request
    description: Generate incident postmortem documentation
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
    timeout: PT60S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "Generate a comprehensive postmortem document:\n\nINCIDENT: {{ inputs.incident_data.id }}\nSERVICE: {{ inputs.incident_data.service }}\nSEVERITY: {{ inputs.incident_data.severity }}\nTITLE: {{ inputs.incident_data.title }}\nTIMESTAMP: {{ inputs.incident_data.timestamp }}\nANALYSIS: {{ outputs.parse_ai_analysis.vars.stdout }}\n\nInclude:\n1. EXECUTIVE SUMMARY (3-4 sentences)\n2. INCIDENT TIMELINE\n3. ROOT CAUSE ANALYSIS\n4. IMPACT ASSESSMENT\n5. RESOLUTION STEPS\n6. ACTION ITEMS (P0, P1, P2)\n7. LESSONS LEARNED\n8. PREVENTION MEASURES\n\nFormat as structured markdown."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.4,
          "maxOutputTokens": 4000
        }
      }

  # Task 8: Get incident UUID from Supabase
  - id: get_incident_uuid
    type: io.kestra.plugin.core.http.Request
    description: Lookup incident UUID by external_id
    uri: "{{ kv('SUPABASE_URL') }}/rest/v1/incidents"
    method: GET
    headers:
      apikey: "{{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
      Authorization: "Bearer {{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
    contentType: application/json
    queryString:
      external_id: "eq.{{ inputs.incident_data.id }}"
      organization_id: "eq.{{ inputs.incident_data.organization_id }}"
      select: "id,organization_id"

  # Task 9: Save AI analysis to Supabase
  - id: save_ai_analysis
    type: io.kestra.plugin.core.http.Request
    description: Save AI analysis results to Supabase ai_analyses table
    uri: "{{ kv('SUPABASE_URL') }}/rest/v1/ai_analyses"
    method: POST
    headers:
      apikey: "{{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
      Authorization: "Bearer {{ kv('SUPABASE_SERVICE_ROLE_KEY') }}"
      Content-Type: application/json
      Prefer: return=representation
    body: |
      {
        "incident_id": "{{ outputs.get_incident_uuid.body | first | jq('.id') | first }}",
        "organization_id": "{{ inputs.incident_data.organization_id }}",
        "kestra_execution_id": "{{ execution.id }}",
        "analysis": {{ outputs.parse_ai_analysis.vars.stdout | json }},
        "remediation": {{ outputs.ai_agent_remediation.body | jq('.candidates[0].content.parts[0].text') | first | json }},
        "documentation": {{ outputs.ai_agent_documentation.body | jq('.candidates[0].content.parts[0].text') | first | json }},
        "confidence_level": "{{ outputs.parse_ai_analysis.vars.stdout | fromJson | jq('.root_cause_confidence') | first | default('MEDIUM') }}"
      }

  # Task 10: Log completion
  - id: log_completion
    type: io.kestra.plugin.core.log.Log
    message: |
      ========================================
      ‚úÖ INCIDENT ANALYSIS COMPLETE
      ========================================
      Incident ID: {{ inputs.incident_data.id }}
      Service: {{ inputs.incident_data.service }}
      Severity: {{ inputs.incident_data.severity }}
      Kestra Execution: {{ execution.id }}
      
      AI Agents Used:
      1. Historical Data Agent - Fetched similar incidents from Supabase
      2. Analysis Agent - Root cause and impact analysis
      3. Remediation Agent - Specific fix recommendations
      4. Documentation Agent - Postmortem generation
      
      Results saved to Supabase ai_analyses table.
      View at: https://incident-scribe.vercel.app/incident/{{ inputs.incident_data.id }}
      ========================================

triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: incident-webhook-key
    description: Trigger analysis via webhook from monitoring tools or frontend

outputs:
  - id: incident_id
    type: STRING
    value: "{{ inputs.incident_data.id }}"
    description: External incident identifier

  - id: severity
    type: STRING
    value: "{{ inputs.incident_data.severity | upper }}"
    description: Incident severity level

  - id: service
    type: STRING
    value: "{{ inputs.incident_data.service }}"
    description: Affected service name

  - id: organization_id
    type: STRING
    value: "{{ inputs.incident_data.organization_id }}"
    description: Organization UUID

  - id: execution_id
    type: STRING
    value: "{{ execution.id }}"
    description: Kestra execution ID for tracking

  - id: analysis_saved
    type: STRING
    value: "true"
    description: Indicates if analysis was saved to Supabase

errors:
  - id: handle_error
    type: io.kestra.plugin.core.log.Log
    message: |
      ‚ùå INCIDENT ANALYSIS FAILED
      Incident: {{ inputs.incident_data.id }}
      Error: {{ task.errorMessage }}
      
      Please check Kestra logs and retry if needed.
      Ensure KV store has GEMINI_API_KEY, SUPABASE_URL, and SUPABASE_SERVICE_ROLE_KEY configured.
