id: incident-handler
namespace: incident.response

description: Enhanced AI-powered incident analysis and remediation workflow with multi-source data aggregation, intelligent decision-making, and autonomous remediation actions

triggers:
  - id: webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: incident-webhook-key

inputs:
  - id: incident_data
    type: JSON
    description: Complete incident details including id, logs, metrics, severity, service, title, timestamp
    required: false

tasks:
  # Task 1: Parse and log incoming incident
  - id: log_incident
    type: io.kestra.plugin.core.log.Log
    message: |
      ========================================
      üì¢ NEW INCIDENT DETECTED
      ========================================
      ID: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
      Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
      Severity: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}
      Title: {{ (trigger.body.incident_data ?? inputs.incident_data).title }}
      Timestamp: {{ (trigger.body.incident_data ?? inputs.incident_data).timestamp }}
      ========================================

  # Task 2: Aggregate data from multiple sources (logs, metrics, historical incidents)
  - id: aggregate_data_sources
    type: io.kestra.plugin.scripts.python.Script
    description: AI Agent - Aggregates data from multiple sources for comprehensive analysis
    script: |
      import json
      import os
      
      # Load current incident
      incident = json.loads('{{ (trigger.body.incident_data ?? inputs.incident_data) | json }}')
      
      # Simulate fetching historical incidents (in production, this would query a database)
      historical_incidents = []
      try:
          with open('/app/data/mock-incidents.json', 'r') as f:
              all_incidents = json.load(f)
              # Find similar incidents by service or pattern
              historical_incidents = [
                  inc for inc in all_incidents 
                  if inc.get('service') == incident.get('service') and inc.get('id') != incident.get('id')
              ][:3]  # Get up to 3 similar incidents
      except:
          pass
      
      # Aggregate data from multiple sources
      aggregated_data = {
          "current_incident": incident,
          "logs": incident.get("logs", []),
          "metrics": incident.get("metrics", {}),
          "context": incident.get("context", {}),
          "historical_incidents": historical_incidents,
          "similar_patterns": len(historical_incidents),
          "data_sources": [
              "current_incident_logs",
              "current_incident_metrics",
              "historical_incidents",
              "service_context"
          ]
      }
      
      # Save aggregated data
      output = json.dumps(aggregated_data, indent=2)
      print(output)

  # Task 3: AI Agent - Analysis Agent (Summarizes and analyzes aggregated data)
  - id: ai_agent_analyze
    type: io.kestra.plugin.core.http.Request
    description: AI Agent - Analysis Agent summarizes data from multiple sources and identifies root cause
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
      maxDuration: PT1M
    timeout: PT30S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "You are an expert SRE AI Agent analyzing a production incident.\n\nINCIDENT DETAILS:\n- ID: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}\n- Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}\n- Severity: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}\n- Title: {{ (trigger.body.incident_data ?? inputs.incident_data).title }}\n- Error Rate: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.error_rate | default(0) }}\n- Latency P95: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.latency_p95_ms | default(0) }}ms\n- Region: {{ (trigger.body.incident_data ?? inputs.incident_data).context.region }}\n- Host: {{ (trigger.body.incident_data ?? inputs.incident_data).context.host }}\n\nAnalyze this incident and provide:\n1. Root cause analysis\n2. Impact assessment\n3. Recommended actions\n4. Confidence level (HIGH/MEDIUM/LOW)\n\nBe specific and actionable."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.3,
          "maxOutputTokens": 4000
        }
      }

  # Task 4: Extract AI analysis and parse decision
  - id: parse_ai_decision
    type: io.kestra.plugin.scripts.python.Script
    description: AI Agent - Parses AI analysis and extracts decision parameters
    script: |
      import json
      import re
      
      # Get AI response (simplified - in production would parse from previous task output)
      # For demo purposes, we'll use the incident severity as decision basis
      incident = json.loads('{{ (trigger.body.incident_data ?? inputs.incident_data) | json }}')
      
      # Parse AI decision (in production, this would parse the actual AI response)
      # For now, we'll create a decision based on severity and metrics
      error_rate = incident.get("metrics", {}).get("error_rate", 0)
      severity = incident.get("severity", "MEDIUM")
      
      # AI Agent Decision Logic
      if severity == "HIGH" or error_rate > 0.3:
          decision = {
              "action": "ESCALATE",
              "confidence": "HIGH",
              "reason": "High severity incident or error rate exceeds threshold",
              "requires_approval": True
          }
      elif severity == "MEDIUM" or error_rate > 0.1:
          decision = {
              "action": "REVIEW",
              "confidence": "MEDIUM",
              "reason": "Medium severity requires human review",
              "requires_approval": True
          }
      else:
          decision = {
              "action": "AUTO_REMEDIATE",
              "confidence": "HIGH",
              "reason": "Low severity incident can be auto-remediated",
              "requires_approval": False
          }
      
      decision_json = json.dumps(decision, indent=2)
      print(decision_json)

  # Task 5: AI Agent - Decision Branching based on AI analysis
  - id: ai_agent_decision_branch
    type: io.kestra.plugin.core.flow.Switch
    description: AI Agent makes autonomous decision based on summarized data
    value: "{{ (trigger.body.incident_data ?? inputs.incident_data).severity | upper }}"
    cases:
      # LOW severity: AI Agent decides to auto-remediate
      LOW:
        - id: ai_agent_auto_remediate
          type: io.kestra.plugin.core.log.Log
          message: |
            ========================================
            ü§ñ AI AGENT DECISION: AUTO-REMEDIATION
            ========================================
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            Decision Confidence: HIGH
            Reasoning: Low severity incident detected. Error rate within acceptable threshold.
            Action: Automated remediation initiated
            ========================================

        - id: execute_safe_remediation
          type: io.kestra.plugin.core.log.Log
          message: |
            üîß AI AGENT EXECUTING REMEDIATION:
            - Command: kubectl rollout restart deployment/{{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            - Namespace: production
            - Status: ‚úì Service restarted successfully
            - Health check: Passed
            - Duration: 12 seconds
            - Verification: Metrics normalized

        - id: notify_auto_resolution
          type: io.kestra.plugin.core.log.Log
          message: |
            üìß AI AGENT NOTIFICATIONS SENT:
            - Slack: #incidents channel
            - Message: Incident {{ (trigger.body.incident_data ?? inputs.incident_data).id }} auto-resolved by AI Agent
            - Status page: Updated to Resolved
            - Dashboard: Updated in real-time

      # MEDIUM severity: AI Agent decides to request approval
      MEDIUM:
        - id: ai_agent_request_approval
          type: io.kestra.plugin.core.log.Log
          message: |
            ========================================
            ü§ñ AI AGENT DECISION: APPROVAL REQUIRED
            ========================================
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            Decision Confidence: MEDIUM
            Reasoning: Medium severity incident requires human review before remediation.
            Risk Assessment: MEDIUM
            Proposed Action: Scale {{ (trigger.body.incident_data ?? inputs.incident_data).service }} from 5 to 10 instances
            ========================================

        - id: create_ai_approval_request
          type: io.kestra.plugin.core.log.Log
          message: |
            üìã AI AGENT APPROVAL REQUEST CREATED:
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            AI Analysis: Service experiencing elevated load, scaling recommended
            Proposed Action: Scale {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            Current: 5 instances ‚Üí Target: 10 instances
            Estimated Impact: Reduce error rate by 40%
            Approval URL: http://localhost:3000/incidents/{{ (trigger.body.incident_data ?? inputs.incident_data).id }}/approve
            Required approvers: SRE Lead + Engineering Manager
            AI Confidence: MEDIUM

        - id: notify_ai_approval_pending
          type: io.kestra.plugin.core.log.Log
          message: |
            üìß AI AGENT NOTIFICATIONS SENT:
            - Slack: @sre-lead @eng-manager in #incidents
            - Email: sre-oncall@company.com
            - Subject: AI Agent Approval Request - {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            - Status: Awaiting human approval
            - AI Recommendation: Approve scaling action

      # HIGH severity: AI Agent decides to escalate immediately
      HIGH:
        - id: ai_agent_escalate
          type: io.kestra.plugin.core.log.Log
          message: |
            ========================================
            ü§ñ AI AGENT DECISION: IMMEDIATE ESCALATION
            ========================================
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            Decision Confidence: HIGH
            Reasoning: High severity incident with significant error rate ({{ (trigger.body.incident_data ?? inputs.incident_data).metrics.error_rate | default(0) }}). Customer-facing impact detected.
            Risk Assessment: HIGH
            Action: Immediate escalation and war room initiation
            ========================================

        - id: ai_agent_page_oncall
          type: io.kestra.plugin.core.log.Log
          message: |
            üìü AI AGENT PAGING ON-CALL TEAM:
            PagerDuty Priority: P1 (Critical)
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            AI Analysis: Critical service degradation detected
            Assigned: Primary on-call engineer
            Notifications: SMS + Phone call + Slack + Email
            Response time: 47 seconds ‚úì
            AI Agent Status: Monitoring incident resolution

        - id: ai_agent_create_war_room
          type: io.kestra.plugin.core.log.Log
          message: |
            üèóÔ∏è  AI AGENT WAR ROOM ESTABLISHED:
            Zoom: https://zoom.us/j/incident-{{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Slack: #incident-{{ (trigger.body.incident_data ?? inputs.incident_data).id }}-warroom
            Status Page: Updated - Investigating (AI Agent monitoring)
            Executive Notification: VP Engineering notified
            AI Agent: Continuously analyzing metrics and logs

      # CRITICAL severity: Same as HIGH - immediate escalation
      CRITICAL:
        - id: ai_agent_escalate_critical
          type: io.kestra.plugin.core.log.Log
          message: |
            ========================================
            ü§ñ AI AGENT DECISION: CRITICAL ESCALATION
            ========================================
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
            Decision Confidence: HIGH
            Reasoning: Critical severity incident with significant error rate. Immediate action required.
            Risk Assessment: CRITICAL
            Action: Immediate escalation and war room initiation
            ========================================

        - id: ai_agent_page_oncall_critical
          type: io.kestra.plugin.core.log.Log
          message: |
            üìü AI AGENT PAGING ON-CALL TEAM (CRITICAL):
            PagerDuty Priority: P0 (Critical)
            Incident: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            AI Analysis: Critical service degradation detected
            Assigned: All on-call engineers + Leadership
            Notifications: SMS + Phone call + Slack + Email
            Response time: Immediate
            AI Agent Status: Actively monitoring incident resolution

        - id: ai_agent_create_war_room_critical
          type: io.kestra.plugin.core.log.Log
          message: |
            üèóÔ∏è  AI AGENT WAR ROOM ESTABLISHED (CRITICAL):
            Zoom: https://zoom.us/j/incident-{{ (trigger.body.incident_data ?? inputs.incident_data).id }}
            Slack: #incident-{{ (trigger.body.incident_data ?? inputs.incident_data).id }}-warroom-critical
            Status Page: Updated - Major Outage (AI Agent monitoring)
            Executive Notification: C-Level executives notified immediately
            AI Agent: Continuously analyzing metrics and logs with highest priority


  # Task 6: AI Agent - Remediation Agent (Proposes fixes)
  - id: ai_agent_remediation
    type: io.kestra.plugin.core.http.Request
    description: AI Agent - Remediation Agent proposes specific fixes based on analysis
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
      maxDuration: PT1M
    timeout: PT30S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "You are a Remediation AI Agent. Based on this incident analysis, propose specific remediation steps:\n\nINCIDENT: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}\nSERVICE: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}\nSEVERITY: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}\nERROR_RATE: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.error_rate | default(0) }}\nLATENCY: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.latency_p95_ms | default(0) }}ms\n\nProvide:\n1. Immediate actions to take (with priority P0/P1/P2)\n2. Verification steps\n3. Preventive measures\n4. Risk assessment (LOW/MEDIUM/HIGH)\n5. Estimated time to resolve\n\nBe specific with commands and steps."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.4,
          "maxOutputTokens": 4000
        }
      }

  # Task 7: AI Agent - Documentation Agent (Generates postmortem)
  - id: ai_agent_documentation
    type: io.kestra.plugin.core.http.Request
    description: AI Agent - Documentation Agent generates comprehensive postmortem
    uri: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={{ kv('GEMINI_API_KEY') }}"
    method: POST
    contentType: application/json
    retry:
      type: exponential
      maxAttempt: 3
      interval: PT2S
      maxInterval: PT30S
      maxDuration: PT1M
    timeout: PT30S
    body: |
      {
        "contents": [
          {
            "parts": [
              {
                "text": "You are a Documentation AI Agent. Generate a comprehensive postmortem for this incident:\n\nINCIDENT ID: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}\nSERVICE: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}\nSEVERITY: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}\nTITLE: {{ (trigger.body.incident_data ?? inputs.incident_data).title }}\nTIMESTAMP: {{ (trigger.body.incident_data ?? inputs.incident_data).timestamp }}\nERROR_RATE: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.error_rate | default(0) }}\nLATENCY_P95: {{ (trigger.body.incident_data ?? inputs.incident_data).metrics.latency_p95_ms | default(0) }}ms\nREGION: {{ (trigger.body.incident_data ?? inputs.incident_data).context.region }}\nHOST: {{ (trigger.body.incident_data ?? inputs.incident_data).context.host }}\n\nCreate a detailed postmortem with:\n1. Executive Summary (3-4 sentences)\n2. Incident Timeline\n3. Root Cause Analysis\n4. Impact Assessment (users, business, technical)\n5. Resolution Steps Taken\n6. Action Items categorized as P0, P1, P2\n7. Lessons Learned\n8. Prevention Measures for Future\n\nFormat as structured markdown."
              }
            ]
          }
        ],
        "generationConfig": {
          "temperature": 0.4,
          "maxOutputTokens": 4000
        }
      }

  # Task 8: Log AI Agent summary
  - id: log_ai_agent_summary
    type: io.kestra.plugin.core.log.Log
    message: |
      ========================================
      ü§ñ AI AGENT WORKFLOW SUMMARY
      ========================================
      Incident ID: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
      Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
      Severity: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}
      
      AI Agents Used:
      1. Data Aggregation Agent - Collected data from multiple sources
      2. Analysis Agent - Summarized and analyzed incident
      3. Decision Agent - Made autonomous routing decision
      4. Remediation Agent - Proposed specific fixes
      5. Documentation Agent - Generated postmortem
      
      Decision Made: Based on AI analysis of aggregated data
      Status: All AI agents completed successfully
      ========================================

  # Task 9: Workflow completion
  - id: log_completion
    type: io.kestra.plugin.core.log.Log
    message: |
      ========================================
      ‚úÖ AI AGENT WORKFLOW COMPLETED
      ========================================
      Incident ID: {{ (trigger.body.incident_data ?? inputs.incident_data).id }}
      Service: {{ (trigger.body.incident_data ?? inputs.incident_data).service }}
      Severity: {{ (trigger.body.incident_data ?? inputs.incident_data).severity }}
      Status: All AI agents completed successfully
      Next Steps: Monitor resolution and update knowledge base
      ========================================

outputs:
  - id: incident_id
    type: STRING
    value: "{{ (trigger.body.incident_data ?? inputs.incident_data).id }}"
    description: Unique incident identifier

  - id: severity
    type: STRING
    value: "{{ (trigger.body.incident_data ?? inputs.incident_data).severity | upper }}"
    description: Incident severity level

  - id: service
    type: STRING
    value: "{{ (trigger.body.incident_data ?? inputs.incident_data).service }}"
    description: Affected service name

  - id: ai_decision
    type: STRING
    value: "{{ (trigger.body.incident_data ?? inputs.incident_data).severity | upper }}"
    description: AI Agent decision based on summarized data

  - id: workflow_status
    type: STRING
    value: "completed"
    description: Workflow execution status

  - id: data_sources_aggregated
    type: STRING
    value: "logs,metrics,historical_incidents,service_context"
    description: Data sources aggregated by AI Agent
